#!/bin/bash
set -euo pipefail
IFS=$'\n\t'

# Logging function only on console. So tee is not needed.
log() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') [INFO] $*" 
}

# Function to clean up on exit
cleanup() {
    local exit_code=$?
    log "Starting cleanup..."
    
    # Kill any background processes
    pkill -P $$ || true
    
    log "Cleanup complete. Exiting with code $exit_code"
    exit $exit_code
}

# Set up trap to call cleanup on script exit
trap cleanup EXIT


# Check if required environment variables are set
required_vars=(
    "inputS3Path"
    "outputS3Path"
    "seriesInstanceUID"
    "studyInstanceUID"
    "patientID"
    "transactionToken"
    "fileUploadId"
)

missing_vars=()
for var in "${required_vars[@]}"; do
    if [ -z "${!var:-}" ]; then
        missing_vars+=("$var")
    fi
done

if [ ${#missing_vars[@]} -ne 0 ]; then
    log "Error: The following required environment variables are not set:"
    for var in "${missing_vars[@]}"; do
        log "  - $var"
    done
    exit 1
fi

log "Job parameters:"
log "  Input S3 Path: ${inputS3Path}"
log "  Output S3 Path: ${outputS3Path}"
log "  Series Instance UID: ${seriesInstanceUID}"
log "  Study Instance UID: ${studyInstanceUID}"
log "  Patient ID: ${patientID}"
log "  Transaction Token: ${transactionToken:0:4}...${transactionToken: -4}"  # Show partial token for security
log "  File Upload ID: ${fileUploadId}"


# Check for CUDA availability
log "=== Checking CUDA/GPU Availability ==="
if command -v nvidia-smi &> /dev/null; then
    log "nvidia-smi found, checking GPU status:"
    if nvidia-smi; then
        log "nvidia-smi executed successfully"
    else
        log "Warning: nvidia-smi command failed with exit code $?"
    fi
else
    log "Warning: nvidia-smi not found"
fi

log "Checking CUDA availability with Python:"
python3 -c "
import torch
print(f'PyTorch version: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'CUDA version: {torch.version.cuda}')
    print(f'Number of GPUs: {torch.cuda.device_count()}')
    for i in range(torch.cuda.device_count()):
        print(f'GPU {i}: {torch.cuda.get_device_name(i)}')
        print(f'GPU {i} Memory: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB')
        try:
            free_mem, total_mem = torch.cuda.mem_get_info(i)
            print(f'GPU {i} Memory Free: {free_mem / 1024**3:.1f} GB')
        except:
            print(f'GPU {i} Memory info unavailable')
else:
    print('No CUDA devices available')
" 2>&1 | while IFS= read -r line; do log "$line"; done

log "=== CUDA Check Complete ==="


# Main execution starts here
log "=== nnUNet Autosegmentation Job Started ==="

# Log all arguments for debugging
log "Script arguments: $*"

# Start the DRAW pipeline in a detached screen session so that it can be monitored. 
# The pipeline folder is located at /home/draw/pipeline
# First activate the conda environment called draw
cd /home/draw/pipeline
log "Changed directory to home directory"

source ~/miniconda3/etc/profile.d/conda.sh && conda activate draw
log "Activated conda environment"

# Create parent directory for database before running alembic
log "Creating data directory for database..."
mkdir -p /home/draw/pipeline/data

# Ensure proper ownership and permissions for the data directory
log "Setting proper permissions for data directory..."
chmod 777 /home/draw/pipeline/data
# In case we're running as root in AWS Batch, ensure the draw user owns the directory
if [ "$(whoami)" = "root" ]; then
    chown -R draw:draw /home/draw/pipeline
fi

# Debug: Check directory permissions and ownership
log "Checking data directory permissions..."
ls -la /home/draw/pipeline
whoami
pwd

# AWS Batch specific checks
log "AWS Batch environment checks..."
log "Container user: $(whoami)"
log "Container UID/GID: $(id)"
log "Available disk space:"
df -h /home/draw/pipeline/data/
log "Directory ownership and permissions:"
ls -ld /home/draw/pipeline/data/
log "Parent directory permissions:"
ls -ld /home/draw/pipeline/
log "File system type:"
stat -f /home/draw/pipeline/data/ 2>/dev/null || log "stat -f not available"

# Debug: Check if env.draw.yml exists and is readable
log "Checking env.draw.yml file..."
if [ -f "env.draw.yml" ]; then
    log "env.draw.yml exists"
    log "File size: $(wc -c < env.draw.yml) bytes"
    log "File content with line endings visible:"
    cat -A env.draw.yml
    log "Testing YAML parsing with Python:"
    python -c "
import yaml
try:
    with open('env.draw.yml', 'r') as f:
        data = yaml.safe_load(f)
    print('YAML parsing successful:')
    for key, value in data.items():
        print(f'  {key}: {value}')
except Exception as e:
    print(f'YAML parsing failed: {e}')
    import traceback
    traceback.print_exc()
"
else
    log "ERROR: env.draw.yml file not found"
    ls -la env*
fi

# Debug: Test SQLite directly
log "Testing SQLite database creation directly..."
sqlite3 /home/draw/pipeline/data/test.db "CREATE TABLE test (id INTEGER); DROP TABLE test;" && log "SQLite test successful" || log "SQLite test failed"

echo "2025-09-22 17:10:19 [INFO] Testing SQLite database creation directly..."
sqlite3 /home/draw/pipeline/data/draw.db.sqlite "CREATE TABLE IF NOT EXISTS test (id INTEGER);" && echo "2025-09-22 17:10:19 [INFO] SQLite test successful" || echo "2025-09-22 17:10:19 [ERROR] SQLite test failed"

echo "2025-09-22 17:10:19 [INFO] Testing SQLite journal file creation (transaction test)..."
sqlite3 /home/draw/pipeline/data/draw.db.sqlite "BEGIN TRANSACTION; INSERT INTO test VALUES (1); COMMIT;" && echo "2025-09-22 17:10:19 [INFO] SQLite transaction test successful" || echo "2025-09-22 17:10:19 [ERROR] SQLite transaction test failed"

echo "2025-09-22 17:10:19 [INFO] Checking for journal files after transaction..."
ls -la /home/draw/pipeline/data/

rm -f /home/draw/pipeline/data/draw.db.sqlite*

# Next we need to create the database using alembic
# First check if alembic is available in the conda environment
if [ -z "$(which alembic)" ]; then
    log "Error: alembic is not available in the conda environment"
    exit 1
else
    log "alembic is available in the conda environment"
fi 

# Debug: Test the exact same environment loading that Alembic uses
log "Testing Alembic environment loading..."
python -c "
import sys
sys.path.insert(0, '.')
try:
    from draw.config import YML_ENV
    print('YML_ENV loaded successfully:')
    for key, value in YML_ENV.items():
        print(f'  {key}: {value}')
    print(f'DB_URL specifically: {YML_ENV[\"DB_URL\"]}')
except Exception as e:
    print(f'Error loading YML_ENV: {e}')
    import traceback
    traceback.print_exc()
"

# Create database using alembic
log "Running alembic upgrade to create database..."

# Test SQLite permissions before running Alembic
log "Testing SQLite database creation permissions..."
test_db_path="/home/draw/pipeline/data/test_permissions.db"
if sqlite3 "$test_db_path" "CREATE TABLE test (id INTEGER); INSERT INTO test VALUES (1); SELECT * FROM test; DROP TABLE test;" 2>/dev/null; then
    log "SQLite permissions test: SUCCESS"
    rm -f "$test_db_path"
else
    log "ERROR: SQLite permissions test FAILED - cannot create database files"
    log "This indicates a file system permission issue in the AWS Batch environment"
    exit 1
fi

# Run Alembic with detailed error handling
log "Running Alembic upgrade with error handling..."
if ! alembic upgrade head 2>&1; then
    log "ERROR: Alembic upgrade failed"
    log "Checking Alembic configuration..."
    log "Alembic version: $(alembic --version 2>&1 || echo 'Alembic not found')"
    log "Current directory: $(pwd)"
    log "Alembic.ini exists: $(test -f alembic.ini && echo 'YES' || echo 'NO')"
    log "Alembic script location: $(test -d draw/alembic && echo 'YES' || echo 'NO')"
    
    # Try to get more detailed error information
    log "Attempting Alembic current to check database state..."
    alembic current 2>&1 || log "Alembic current command failed"
    
    log "Attempting Alembic history to check migrations..."
    alembic history 2>&1 || log "Alembic history command failed"
    
    exit 1
fi

log "Alembic upgrade completed successfully"


# Check if the database is created successfully. The database is created as a sqlite database called draw.db.sqlite in the data directory.
if [ ! -f /home/draw/pipeline/data/draw.db.sqlite ]; then
    log "Error: Database is not created successfully"
    exit 1
else
    log "Database is created successfully"
fi

# Delete the output directory if it exists and recreate it
log "Preparing output directory..."
rm -rf /home/draw/pipeline/output
mkdir -p /home/draw/pipeline/output

# Create parent directory if it doesn't exist
mkdir -p /home/draw/pipeline/data

# Create the symlink
log "Creating nnUNet results symlink..."

# Ensure target directory exists
mkdir -p /home/draw/pipeline/data

# Debug: Check the contents of the data directory 
log "Listing contents of data directory (/home/draw/pipeline/data):"
ls -la /home/draw/pipeline/data

# Remove any existing symlink or directory
if [ -e "/home/draw/pipeline/data/nnUNet_results" ]; then
    rm -rf "/home/draw/pipeline/data/nnUNet_results"
fi

# Create the symlink
ln -sf /mnt/efs/nnUNet_results /home/draw/pipeline/data/nnUNet_results

# Create th nnUNet_raw and nnUNet_preprocessed directories
mkdir -p /home/draw/pipeline/data/nnUNet_raw
mkdir -p /home/draw/pipeline/data/nnUNet_preprocessed



# Verify and log EFS mount directory contents
if [ -d "/mnt/efs/nnUNet_results" ]; then
    log "Listing contents of EFS mount directory (/mnt/efs/nnUNet_results):"
    if ! ls -RS /mnt/efs/nnUNet_results 2>/dev/null; then
        log "Warning: Failed to list EFS contents"
    fi
else
    log "Error: EFS directory /mnt/efs/nnUNet_results does not exist"
    exit 1
fi

# Check EFS filesystem type and permissions
df -Th /mnt/efs
ls -ld /mnt/efs /home/draw/pipeline/data
mount | grep efs

# Verify and log symlink directory contents
if [ -L "/home/draw/pipeline/data/nnUNet_results" ]; then
    log "Listing contents of symlink directory (/home/draw/pipeline/data/nnUNet_results):"
    if ! ls -RS /home/draw/pipeline/data/nnUNet_results 2>/dev/null; then
        log "Error: Failed to list symlink contents - check permissions or target"
        exit 1
    fi
else
    log "Error: Symlink /home/draw/pipeline/data/nnUNet_results does not exist or is not a symlink"
    exit 1
fi

# Verify the contents of the data directory
log "Listing contents of data directory (/home/draw/pipeline/data):"
ls -la /home/draw/pipeline/data

#
# Create necessary directories
log "Creating necessary directories..."
mkdir -p /home/draw/pipeline/logs
mkdir -p /home/draw/copy_dicom/files

# Set nnU-Net environment variables
log "Exporting nnU-Net environment variables..."
export base_directory="/home/draw/pipeline/data" # Added to allow proper postprocessing path resolution.
export nnUNet_raw="/home/draw/pipeline/data/nnUNet_raw"
export nnUNet_preprocessed="/home/draw/pipeline/data/nnUNet_preprocessed"
export nnUNet_results="/home/draw/pipeline/data/nnUNet_results"
log "nnUNet_raw: ${nnUNet_raw}"
log "nnUNet_preprocessed: ${nnUNet_preprocessed}"
log "nnUNet_results: ${nnUNet_results}"

# Start the pipeline directly in background
log "Starting the pipeline directly in background..."
source ~/miniconda3/etc/profile.d/conda.sh
conda activate draw
nohup python main.py start-pipeline > /home/draw/pipeline/logs/pipeline_output.log 2>&1 &
pipeline_pid=$!
log "Pipeline started with PID: $pipeline_pid"

# Wait for pipeline to start
log "Waiting for pipeline to initialize..."
sleep 30


# Download DICOM zip from S3
local_zip_path="/home/draw/copy_dicom/file_upload_${fileUploadId}_dicom.zip"
log "Downloading DICOM zip from ${inputS3Path}..."
if ! aws s3 cp "${inputS3Path}" "${local_zip_path}"; then
    log "Error: Failed to download DICOM zip from S3"
    exit 1
fi

# Verify zip file exists and is not empty
if [[ ! -s "${local_zip_path}" ]]; then
    log "Error: Downloaded DICOM zip is empty or not found"
    exit 1
fi

# Create a temporary subdirectory named after the series instance UID
temp_series_dir="/home/draw/copy_dicom/${seriesInstanceUID}"
log "Creating temporary directory for extraction: ${temp_series_dir}"
rm -rf "${temp_series_dir}"
mkdir -p "${temp_series_dir}"

# Extract the zip file directly into the new temporary directory
log "Extracting DICOM files to ${temp_series_dir}..."
if ! unzip -q "${local_zip_path}" -d "${temp_series_dir}"; then
    log "Error: Failed to extract DICOM zip"
    exit 1
fi

# Define the final watch directory path
watch_dir="/home/draw/pipeline/dicom"
series_dir="${watch_dir}/${seriesInstanceUID}"

# Move the entire populated temporary directory to the watch directory
log "Moving '${temp_series_dir}' to '${watch_dir}/'"
if ! mv "${temp_series_dir}" "${watch_dir}/"; then
    log "Error: Failed to move series directory to watch path"
    exit 1
fi

log "Successfully moved DICOM files to series directory: ${series_dir}"

# Count the number of files that are in the series directory
log "Counting number of files in series directory..."
file_count=$(find "${series_dir}" -type f -name "*.dcm" | wc -l)
log "Number of DICOM files in series directory: $file_count"

# Also count total files in watch directory for reference
total_files=$(find /home/draw/pipeline/dicom -type f | wc -l)
log "Total files in watch directory: $total_files"

# Check if the logfile has been created at the logs directory
# Retry for 5 minutes at 1 minute intervals before giving up and raising an error
log "Waiting for pipeline log file to be created..."
log_found=false
for i in {1..5}; do
    if [ -f /home/draw/pipeline/logs/logfile.log ]; then
        log "Log file found"
        cat /home/draw/pipeline/logs/logfile.log
        log_found=true
        
        break
    fi
    sleep 60
    log "Log file not found, retrying... ($i/5)"
done    
if [ "$log_found" = false ]; then
    log "Error: Log file not found after 5 minutes of waiting"
    exit 1
fi


# Check if watchdog is running
log "Checking if watchdog process is running..."
watchdog_found=false
max_watchdog_attempts=10  # 5 minutes / 30 seconds = 10 attempts

# Check pipeline process status
log "=== PIPELINE PROCESS STATUS ==="
log "Checking if pipeline process is still running..."
if kill -0 $pipeline_pid 2>/dev/null; then
    log "Pipeline process (PID: $pipeline_pid) is running"
else
    log "Pipeline process (PID: $pipeline_pid) is not running"
fi

# Show pipeline output log
log "Pipeline output log:"
if [ -f /home/draw/pipeline/logs/pipeline_output.log ]; then
    log "=== PIPELINE OUTPUT LOG ==="
    cat /home/draw/pipeline/logs/pipeline_output.log
    log "=== END PIPELINE OUTPUT LOG ==="
else
    log "Pipeline output log not found"
fi

log "=== END PIPELINE PROCESS STATUS ==="

for attempt in $(seq 1 $max_watchdog_attempts); do
    log "Watchdog check attempt $attempt/$max_watchdog_attempts..."
    
    # Show all current processes for debugging
    log "All current processes (filtered for relevant ones):"
    ps aux | head -1  # Show header
    ps aux | grep -E "(python|main\.py|start-pipeline|TASK_|draw)" | grep -v grep || log "No relevant processes found"
    
    # Check for Python processes related to the pipeline
    watchdog_processes=$(ps aux | grep -E "(python.*main\.py|python.*start-pipeline|python.*TASK_copy|python.*task_watch_dir)" | grep -v grep | wc -l)
    
    log "Found $watchdog_processes watchdog-related processes"
    
    if [ "$watchdog_processes" -gt 0 ]; then
        log "Watchdog process details:"
        ps aux | grep -E "(python.*main\.py|python.*start-pipeline|python.*TASK_copy|python.*task_watch_dir)" | grep -v grep
        watchdog_found=true
        break
    else
        log "No specific watchdog processes found"
        
        # Check for any Python processes at all
        python_processes=$(ps aux | grep python | grep -v grep | wc -l)
        log "Total Python processes running: $python_processes"
        
        # Also check for python3 specifically
        python3_processes=$(ps aux | grep python3 | grep -v grep | wc -l)
        log "Python3 processes running: $python3_processes"
        
        # Check for conda python processes
        conda_python_processes=$(ps aux | grep -E "(conda|miniconda)" | grep python | grep -v grep | wc -l)
        log "Conda Python processes running: $conda_python_processes"
        
        if [ "$python_processes" -gt 0 ]; then
            log "=== ALL PYTHON PROCESSES ==="
            log "Process header:"
            ps aux | head -1
            log "All Python processes (including python, python3, and conda environments):"
            ps aux | grep -E "(python|python3)" | grep -v grep
            log "=== END PYTHON PROCESSES ==="
        else
            log "No Python processes found at all"
        fi
        
        # Additional check for any processes containing 'draw' or 'pipeline'
        draw_processes=$(ps aux | grep -E "(draw|pipeline)" | grep -v grep | wc -l)
        log "Draw/Pipeline related processes: $draw_processes"
        if [ "$draw_processes" -gt 0 ]; then
            log "Draw/Pipeline process details:"
            ps aux | grep -E "(draw|pipeline)" | grep -v grep
        fi
        
        # Check screen sessions again in each iteration
        log "Re-checking screen sessions:"
        screen -ls 2>&1 || log "No screen sessions"
        
        if [ $attempt -lt $max_watchdog_attempts ]; then
            log "Waiting 30 seconds before next watchdog check..."
            sleep 30
        fi
    fi
done

if [ "$watchdog_found" = false ]; then
    log "Error: Watchdog process not found after 5 minutes"
    log "=== FINAL DEBUGGING INFORMATION ==="
    log "Final screen session check:"
    screen -ls 2>&1 || log "No screen sessions found"
    
    log "Final process check:"
    ps aux | grep -E "(python|main|start|pipeline|draw)" | grep -v grep || log "No pipeline-related processes found"
    
    log "Checking if screen session died - looking for any detached sessions:"
    screen -wipe 2>&1 || log "Screen wipe failed or no sessions"
    
    log "Checking system logs for screen/python errors:"
    tail -20 /var/log/syslog 2>/dev/null || log "Cannot access system logs"
    
    log "=== END FINAL DEBUGGING ==="
    exit 1
fi

log "Watchdog check completed successfully - file monitoring is active"




# Check the newly created database using alembic. 
# This database is created in the previous step
# If not repeat the check for at least 5 minutes at 30 sec interval before exiting. 
# The database definition is available at alembic\versions\de871710e5d0_db_config.py. The column name to search for is series_name
# The series instance UID value will match the series instance UID available in the environment variables. seriesInstanceUID

log "Checking database for series instance UID: ${seriesInstanceUID}"
db_check_found=false
max_attempts=10  # 5 minutes / 30 seconds = 10 attempts

for attempt in $(seq 1 $max_attempts); do
    log "Database check attempt $attempt/$max_attempts..."
    
    # Query the database using sqlite3 to check if series_name exists with INIT status
    db_result=$(sqlite3 /home/draw/pipeline/data/draw.db.sqlite \
        "SELECT COUNT(*) FROM dicomlog WHERE series_name = '${seriesInstanceUID}' ;" 2>/dev/null || echo "0")
    
    if [ "$db_result" -gt 0 ]; then
        log "Found series instance UID '${seriesInstanceUID}' in database"
        db_check_found=true
        break
    else
        # Check if the series exists with any status
        series_exists=$(sqlite3 /home/draw/pipeline/data/draw.db.sqlite \
            "SELECT COUNT(*) FROM dicomlog WHERE series_name = '${seriesInstanceUID}';" 2>/dev/null || echo "0")
        
        if [ "$series_exists" -gt 0 ]; then
            # Get the current status
            current_status=$(sqlite3 /home/draw/pipeline/data/draw.db.sqlite \
                "SELECT status FROM dicomlog WHERE series_name = '${seriesInstanceUID}' LIMIT 1;" 2>/dev/null || echo "UNKNOWN")
            log "Series instance UID '${seriesInstanceUID}' found with status: $current_status"
        else
            log "Series instance UID '${seriesInstanceUID}' not found in database yet"
        fi
        
        if [ $attempt -lt $max_attempts ]; then
            log "Waiting 30 seconds before next attempt..."
            sleep 30
        fi
    fi
done

if [ "$db_check_found" = false ]; then
    log "Error: Series instance UID '${seriesInstanceUID}' with INIT status not found in database after 5 minutes"
    cat /home/draw/pipeline/logs/pipeline_output.log
    log "=== DATABASE DEBUGGING INFORMATION ==="
    
    # Check if database file exists
    if [ ! -f /home/draw/pipeline/data/draw.db.sqlite ]; then
        log "ERROR: Database file does not exist at /home/draw/pipeline/data/draw.db.sqlite"
    else
        log "Database file exists, size: $(stat -c%s /home/draw/pipeline/data/draw.db.sqlite) bytes"
        
        # Check database file permissions
        log "Database file permissions: $(ls -la /home/draw/pipeline/data/draw.db.sqlite)"
        
        # Test basic SQLite connectivity
        log "Testing SQLite connectivity..."
        sqlite_test=$(sqlite3 /home/draw/pipeline/data/draw.db.sqlite "SELECT 1;" 2>&1)
        if [ $? -eq 0 ]; then
            log "SQLite connectivity: SUCCESS"
        else
            log "SQLite connectivity: FAILED - $sqlite_test"
        fi
        
        # Check if the dicomlog table exists
        log "Checking if dicomlog table exists..."
        table_exists=$(sqlite3 /home/draw/pipeline/data/draw.db.sqlite \
            "SELECT name FROM sqlite_master WHERE type='table' AND name='dicomlog';" 2>&1)
        if [ -n "$table_exists" ]; then
            log "dicomlog table exists"
        else
            log "dicomlog table does NOT exist!"
            log "Available tables:"
            sqlite3 /home/draw/pipeline/data/draw.db.sqlite \
                "SELECT name FROM sqlite_master WHERE type='table';" 2>&1 || log "Failed to list tables"
        fi
        
        # Get total record count with detailed error handling
        log "Querying record count..."
        total_records_result=$(sqlite3 /home/draw/pipeline/data/draw.db.sqlite \
            "SELECT COUNT(*) FROM dicomlog;" 2>&1)
        if [ $? -eq 0 ]; then
            log "Total records in dicomlog table: $total_records_result"
        else
            log "Failed to count records: $total_records_result"
        fi
        
        # Only proceed with detailed queries if table exists
        if [ -n "$table_exists" ]; then
            # Show all records in the database
            log "Querying all records in dicomlog table..."
            all_records_result=$(sqlite3 /home/draw/pipeline/data/draw.db.sqlite \
                "SELECT 'ID: ' || id || ', Series: ' || series_name || ', Status: ' || status || ', Model: ' || model || ', Created: ' || created_on FROM dicomlog ORDER BY created_on DESC;" 2>&1)
            if [ $? -eq 0 ]; then
                log "All records in dicomlog table:"
                echo "$all_records_result"
            else
                log "Failed to query all records: $all_records_result"
            fi
            
            # Show records by status
            log "Querying records grouped by status..."
            status_groups_result=$(sqlite3 /home/draw/pipeline/data/draw.db.sqlite \
                "SELECT status || '|' || COUNT(*) FROM dicomlog GROUP BY status;" 2>&1)
            if [ $? -eq 0 ]; then
                log "Records grouped by status:"
                echo "$status_groups_result"
            else
                log "Failed to query status groups: $status_groups_result"
            fi
            
            # Check if our specific series exists with any status
            log "Checking for our specific series..."
            our_series_result=$(sqlite3 /home/draw/pipeline/data/draw.db.sqlite \
                "SELECT COUNT(*) FROM dicomlog WHERE series_name = '${seriesInstanceUID}';" 2>&1)
            
            if [ $? -eq 0 ] && [ "$our_series_result" -gt 0 ]; then
                log "Our series '${seriesInstanceUID}' exists in database with details:"
                series_details=$(sqlite3 /home/draw/pipeline/data/draw.db.sqlite \
                    "SELECT 'ID: ' || id || ', Status: ' || status || ', Model: ' || model || ', Input: ' || input_path || ', Output: ' || COALESCE(output_path, 'NULL') || ', Created: ' || created_on FROM dicomlog WHERE series_name = '${seriesInstanceUID}';" 2>&1)
                if [ $? -eq 0 ]; then
                    echo "$series_details"
                else
                    log "Failed to query our series details: $series_details"
                fi
            else
                log "Our series '${seriesInstanceUID}' does NOT exist in database"
                log "Listing all series names in database..."
                series_names_result=$(sqlite3 /home/draw/pipeline/data/draw.db.sqlite \
                    "SELECT DISTINCT series_name FROM dicomlog ORDER BY series_name;" 2>&1)
                if [ $? -eq 0 ]; then
                    log "All series names in database:"
                    echo "$series_names_result"
                else
                    log "Failed to query series names: $series_names_result"
                fi
            fi
        else
            log "Skipping detailed queries since dicomlog table does not exist"
        fi
    fi
    
    log "=== END DATABASE DEBUGGING ==="
    exit 1
fi

log "Database check completed successfully - series ready for processing"



# Wait for the automatic segmentation to complete by checking for AUTOSEGMENT.RT.dcm
log "Waiting for auto-segmentation to complete..."

# Check if file already exists (search recursively in output directory)
autosegment_file=$(find /home/draw/pipeline/output -name "AUTOSEGMENT.RT.dcm" -type f 2>/dev/null | head -n 1)
if [ -n "$autosegment_file" ]; then
    log "Auto-segmentation file already exists at: $autosegment_file"
else
    # Use polling approach with proper 20-minute timeout
    auto_segment_file_found=false
    start_time=$(date +%s)
    timeout_duration=1200  # 20 minutes
    check_interval=5       # Check every 5 seconds
    
    log "Starting polling for auto-segmentation file with 20-minute timeout..."
    log "Searching recursively in /home/draw/pipeline/output for AUTOSEGMENT.RT.dcm"
    
    while [ $(($(date +%s) - start_time)) -lt $timeout_duration ]; do
        # Check if the file exists anywhere in the output directory
        autosegment_file=$(find /home/draw/pipeline/output -name "AUTOSEGMENT.RT.dcm" -type f 2>/dev/null | head -n 1)
        if [ -n "$autosegment_file" ]; then
            elapsed_time=$(($(date +%s) - start_time))
            log "Auto-segmentation file found after ${elapsed_time} seconds at: $autosegment_file"
            auto_segment_file_found=true
            break
        fi
        
        # Log progress every minute (12 checks * 5 seconds = 60 seconds)
        checks_done=$(( ($(date +%s) - start_time) / check_interval ))
        if [ $((checks_done % 12)) -eq 0 ] && [ $checks_done -gt 0 ]; then
            elapsed_minutes=$(( ($(date +%s) - start_time) / 60 ))
            log "Auto-segmentation file not found yet, waiting... (${elapsed_minutes} minutes elapsed)"
        fi
        
        # Sleep for the check interval
        sleep $check_interval
    done
    
    if [ "$auto_segment_file_found" = false ]; then
        log "Error: Auto-segmentation file not found after 20 minutes of waiting"
        log "Contents of the log file:"
        cat /home/draw/pipeline/logs/logfile.log

        log "Attempting to find and re-run the failed nnUNetv2_predict command..."
        
        # Extract the command from the log file
        failed_command=$(grep -o "Command '\['nnUNetv2_predict'.*'\]' returned non-zero exit status 1" /home/draw/pipeline/logs/logfile.log | head -n 1)

        if [ -n "$failed_command" ]; then
            log "Found failing command: $failed_command"
            
            # Clean up the command string for execution
            # Use Python to reliably parse the command string, avoiding sed quoting issues.
            executable_command=$(python3 -c "
import sys
import shlex

log_line = sys.stdin.read()
# Extract the list-like string: ['nnUNet...', '...', ...]
try:
    command_list_str = log_line[log_line.find('['):log_line.rfind(']') + 1]
    # Safely evaluate the string representation of the list
    command_list = eval(command_list_str)
    # Join the list elements into a shell-safe string
    print(' '.join(shlex.quote(arg) for arg in command_list))
except Exception as e:
    print(f'Error parsing command: {e}', file=sys.stderr)
    exit(1)
" <<< "$failed_command")
            
            log "Executing the command directly to see the error..."
            
            # Activate conda env and run
            source ~/miniconda3/etc/profile.d/conda.sh && conda activate draw
            
            # Run the command
            eval "$executable_command"
            
            log "Command execution finished. The error above is the direct output from the failed command."
        else
            log "Could not find the failing nnUNetv2_predict command in the log file."
            log "Contents of the dicomlog table for debugging:"
            python3 -c "
import sqlite3
import os

db_path = '/home/draw/pipeline/data/draw.db.sqlite'
table_name = os.environ.get('TABLE_NAME', 'dicomlog')

try:
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # Get column names
    cursor.execute(f'PRAGMA table_info({table_name})')
    columns = [col[1] for col in cursor.fetchall()]
    
    # Get all records from the table
    cursor.execute(f'SELECT * FROM {table_name}')
    rows = cursor.fetchall()
    
    if not rows:
        print(f'No records found in {table_name} table')
    else:
        print(f'Found {len(rows)} records in {table_name} table:')
        print('Columns: ' + ', '.join(columns))
        print('-' * 80)
        
        for i, row in enumerate(rows, 1):
            print(f'Record {i}:')
            for col, val in zip(columns, row):
                print(f'  {col}: {val}')
            print('-' * 40)
    
    conn.close()
    
except Exception as e:
    print(f'Error querying database: {e}')
"
        fi
        exit 1
    fi
fi

# Wait briefly before final copy to ensure all writes are complete
log "Waiting for 15 seconds for final writes to complete..."
sleep 15

# Find the actual autosegmentation file path (in case it wasn't found during the polling above)
if [ -z "$autosegment_file" ]; then
    autosegment_file=$(find /home/draw/pipeline/output -name "AUTOSEGMENT.RT.dcm" -type f 2>/dev/null | head -n 1)
fi

# Define output file paths
local_output_file="$autosegment_file"
s3_output_path="${outputS3Path}/AUTOSEGMENT.RT.${fileUploadId}.dcm"

# Verify output file exists and is not empty
if [[ ! -s "${local_output_file}" ]]; then
    log "Error: Output file is empty or not found at ${local_output_file}"
    log "Searched for AUTOSEGMENT.RT.dcm in /home/draw/pipeline/output directory"
    exit 1
fi

log "Output file size: $(stat -c%s "${local_output_file}") bytes"

# Upload the result to S3
log "Uploading result to ${s3_output_path}..."
if ! aws s3 cp "${local_output_file}" "${s3_output_path}"; then
    log "Error: Failed to upload result to S3"
    exit 1
fi

# Verify the upload was successful
if ! aws s3 ls "${s3_output_path}" &>/dev/null; then
    log "Error: Failed to verify S3 upload"
    exit 1
fi

log "Auto-segmentation completed successfully"
log "Result available at: ${s3_output_path}"
log "Final pipeline log:"
if [ -f /home/draw/pipeline/logs/pipeline.log ]; then
    cat /home/draw/pipeline/logs/pipeline.log
fi

# Exit with success
exit 0